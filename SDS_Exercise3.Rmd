---
title: "SDS_Exercise3"
output: github_document
---

```{r setup, include=FALSE}
########### Predictive model building ############

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mosaic)
library(FNN)
library(ggplot2)
library(LICORS)  # for kmeans++
library(foreach)

greenbuildings = read.csv("data/greenbuildings.csv")
wine = read.csv("data/wine.csv")
social_marketing = read.csv("data/social_marketing.csv")
set.seed(3)
rmse = function(y, yhat) {
  sqrt( mean( (y - yhat)^2 ) )
}
n = nrow(greenbuildings)
n_train = round(0.8*n) # round to nearest integer n_test = n ? n_train
gb_no_green = subset(greenbuildings, green_rating == 0)
gb_no_green$green_rating[gb_no_green$green_rating == 0] <- 1
gb_green = subset(greenbuildings, green_rating == 1)
gb_green$green_rating[gb_green$green_rating == 1] <- 0


rmse_vals = do(100)*{
  
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train+1, replace=FALSE) 
  test_cases = setdiff(1:n, train_cases) 
  buildings_train = greenbuildings[train_cases,] 
  buildings_test = greenbuildings[test_cases,]
  
  lm1 = lm(Rent ~ renovated + size + stories + age + green_rating, data=buildings_test)
  lm2 = lm(Rent ~ (Gas_Costs + Electricity_Costs + total_dd_07)^2 + 
             (age + renovated)^2 + 
             (Gas_Costs + Electricity_Costs + green_rating)^2 +
             stories + 
             cluster_rent + 
             size, data=buildings_test)
  lm4 = lm(Rent ~ amenities + green_rating, data=buildings_test)
  lm5 = lm(Rent ~ Gas_Costs + Electricity_Costs + total_dd_07 + green_rating, data=buildings_test)
  
  # Predictions out of sample
  yhat_test1 = predict(lm1, buildings_test)
  yhat_test2 = predict(lm2, buildings_test)
  yhat_test4 = predict(lm4, buildings_test)
  yhat_test5 = predict(lm5, buildings_test)
  
  nogreen_to_green = predict(lm2, gb_no_green)
  green_to_nogreen = predict(lm2, gb_green)
  
  
  c(rmse(buildings_test$Rent, yhat_test1),
    rmse(buildings_test$Rent, yhat_test4),
    rmse(buildings_test$Rent, yhat_test5),
    rmse(buildings_test$Rent, yhat_test2),
    mean(nogreen_to_green - gb_no_green$Rent),
    mean(green_to_nogreen - gb_green$Rent)
    
  )
}


####### Clustering and PCA #########

# Center and scale the data
summary(wine)
X_wine = wine[, (0:10)]
X_wine = scale(X_wine, center=TRUE, scale=TRUE)

mu = attr(X_wine,"scaled:center")
sigma = attr(X_wine,"scaled:scale")

clust1 = kmeanspp(X_wine, 2, nstart=25)
clust2 = kmeanspp(X_wine, 6, nstart=25)

#clust1$center  # not super helpful
#clust1$center[1,]*sigma + mu
#clust1$center[2,]*sigma + mu


# Which cars are in which clusters?
# which(clust1$cluster == 1)
# which(clust1$cluster == 2)


length(which(wine$color[which(clust1$cluster == 1)] == "white"))
length(which(wine$color[which(clust1$cluster == 1)] == "red"))
length(which(wine$color[which(clust1$cluster == 2)] == "white"))
length(which(wine$color[which(clust1$cluster == 2)] == "red"))

mean(wine$quality[which(clust2$cluster == 1)])
mean(wine$quality[which(clust2$cluster == 2)])
mean(wine$quality[which(clust2$cluster == 3)])
mean(wine$quality[which(clust2$cluster == 4)])

pc2 = prcomp(X_wine, scale=TRUE, rank=2)
loadings = pc2$rotation
scores = pc2$x

qplot(scores[,1], scores[,2], color=wine$color, xlab='Component 1', ylab='Component 2')

######### Social Segmentation #########\

attributes(social_marketing)$name

cols.dont.want <- c("spam", "uncategorized", "adult", "chatter")

social_marketing <- social_marketing[, ! names(social_marketing) %in% cols.dont.want, drop = F]
summary(social_marketing)

X_social = social_marketing[, (2:32)]
summary(X_social)
clust1 = kmeanspp(X_social, 2, nstart=25)
clust2 = kmeanspp(X_social, 3, nstart=25)
clust3 = kmeanspp(X_social, 4, nstart=25)

clust1$centers
clust2$centers
clust3$centers

```



# Predictive Model Building

### Problem
For this first question, our goal was to create a model that would be able to predict the rent of buildings from Exercise 1. From there, we should be able to take that model, and predict the change in rent if a building's green_rating changed.

### Data and Model
We created 3 linear regression models to test various combinations of attributes to see if they were good indicators of Rent. The first (V1) was a combination of attributes related to age and size, the second (V2) was only concerned with amenities, and the last (V3) looked at gas/electricity costs and the number of heating/cool days in the region. All three of these models also used the green_rating. We decided to lump LEED and EnergyStar together for simplicity as we did not see too much difference between the two. The green_rating attribute indicates whether or not the building was green certified.

In our fourth linear regression model (V4), we combined all of these elements and introduced interactions between attributes. We included interactions between gas/electricity costs and total degree days as the number of degree days will affect the cost of gas/electricity. We included an interaction between age and renovation as a building that is old but renovated will likely be more expensive than a building that is only old and not renovated. The final interaction we had was between gas/electricity costs and green_rating, as a building will be more energy efficient if it is a 'green' building, resulting in lower gas/electricity costs. Other than those interactions, we also used stories, size, and cluster_rent as they were good/significant predictors.

We tested these models on 100 different test/training splits. For each split, we created the three linear models on a training set, predicted Rent on a given test set, and calculated RMSE between the four models' predictions and actual values for Rent. We selected different test/training sets for each split.

As for predicting the average change in Rent given a change in green_rating, we took the entire dataset, flipped the green_rating, and predicted the Rent on the entire set using V4 with all other attributes held constant. Once we had that value, we took the mean of the differences between the predicted Rent and actual Rent of every building. We did this within the test/training splits as well.

### Results
```{r green_buildings,  echo=FALSE}

boxplot(rmse_vals[1:4],xlab = "Models", ylab = "RMSE of Rent (dollars/sq ft)", main = "RMSE of Linear Regression Models")
colMeans(rmse_vals[1:4])

```
As seen above, the final model V4 outperforms the other three due to the use of interactions as well as incorporating elements from the other three models.

```{r green_buildings_2,  echo=FALSE}

boxplot(rmse_vals[5:6], xlab = "Changes to Green Rating", ylab = "RMSE of Rent (dollars/sq ft)", main = "Difference in Dollar Amounts")
colMeans(rmse_vals[5:6])

```
V5 indicates the average change in Rent when a building that was previously not green becomes green. V6 indicates the average change in Rent when a building that was previously green becomes not green. As seen above, if a building changes its green rating, the change in Rent is approximately 1 dollar according to our model. That is, rent will be \$1.08 more expensive if a building becomes green, and \$1.05 less expensive if a building loses its green status.

### Conclusion
We were able to create a model using linear regression techniques to predict a building's rent, where the average RMSE of our model was 9.34. From that model, we were able to project the change in rent given a change in a building's green_rating while all other factors constant. It appears if a building's green_rating status changes, the change in rent will be around a dollar, either more expensive if the building was previously not green or less expensive if the building was previously green.


# What Causes What

### Question 1
The podcast talks about how the data is quite messy because high crime cities have an incentive to hire a lot of police. This creates a direct relation between police and crime, and causes the number of police present depend on the crime and skews how the relation looks the other way around.

### Question 2
The researchers were able to use Washington D.C.'s terrorism alert system to create a situation where more police happened to be present for reasons unrelated to crime. This let them ask on these alert days what happens to crime when there are more police present on the street and in various areas. The table shows how on high alert days, crime rate is decreased by 5%. They were able to verify that the crime rate did not decrease because people were scared of a terrorist threat by tracking the number of people who took the metro. The number of people taking metro barely changed, indicating that the number of people that stayed inside due to a terrorist threat on these alert days did not change significantly.

### Question 3
They were trying to see whether or not people were staying inside because there was a terrorist threat. People staying at home rather than robbing stores would explain the decrease in crime rather than the extra number of police. However, they saw that the number of riders in the metro (essentially the number of possible victims) did not change significantly between high alert days and normal days. This meant that the decrease in crime rate in D.C. was most likely caused by the higher number of police that were present during these high alert days.

### Question 4
The model is estimating the reduction in crime on high alert days in various districts. It can be seen that the district in D.C. has significant decrease in crime rate in comparison to other districts that did not have an increase in police during high alert days. This implies the number of police present decreases the crime rate.


# Clustering and PCA


## The data
We are given data on the chemical properties of 6500 different bottles of vinho verde wine from northern Portugal. We are also given the color of each bottle of wine, and it's quality as determined by a panel of wine tasters. The goal is to determine if various methods of dimensionality reduction are capable of separating the bottles of wine by color and quality using only their chemical properties

## PCA

The first method we will test is Principle Component Analysis. Here is a biplot of the first 2 PC's of a second order PCA of the data:

```{r PCA,  echo=FALSE}

qplot(scores[,1], scores[,2], color=wine$color, xlab='Component 1', ylab='Component 2')  + scale_color_manual(values=c("red", "yellow"))

```

The first PC axis seems to primarily assign red wines negative values and white wines positive values. Examining PC1 further, these are the 11 chemical properties sorted from most negatively associated with PC1 to most positively assoiated:

```{r PCA_2,  echo=FALSE}

loadings[,1] %>% sort %>% head(20)

```

## K-means++

The next method we will test is K-means++ clustering. With k=2 and nstart=25, we get two clusters, the first consisting of `r length(which(wine$color[which(clust1$cluster == 1)] == "white"))` white wines and `r length(which(wine$color[which(clust1$cluster == 1)] == "red")) ` red wines, and the second consisting of `r length(which(wine$color[which(clust1$cluster == 2)] == "white"))` white wines and `r length(which(wine$color[which(clust1$cluster == 2)] == "red"))` red wines, indicating that k-means++ is very capable of distinguishing between red and white wines.

## Quality 

We will now determine if k-means++ is also capable of distinguishing the quality of wine based on it's chemical properties by using a larger number of clusters. Running k-means++ on the same data but using k=4 instead we get 4 clusters with a respective average quality of `r mean(wine$quality[which(clust2$cluster == 1)]) `, `r mean(wine$quality[which(clust2$cluster == 2)]) `,
`r mean(wine$quality[which(clust2$cluster == 3)])`, and
`r mean(wine$quality[which(clust2$cluster == 4)])` respectively. These all are all very close to both each other and the average quality of the entire data set, indicating that k-means++ did not significantly separate the wines based on quality in this case.

## Conclusion

While both methods seem to be able to distinguish wine color, we believe that k-means++ makes more sense than PCA for this data set because the size of the data set is much larger than the number of attributes used. However principal component analysis did reveal some potentially useful information. Namely that qualities like high volatile acidity and chloride composition are associated with red wines and qualities like residual sugar and sulfur dioxide are associated with white wines. However, k-means++ was not able to distinguish the quality of wines. More research would be needed to determine if this is a failure of the choice of technique or if these specific chemical properties are not indicative of quality. 

# Market segmentation

## The data

We have the twitter data of a sample of Twitter accounts that follow the NutrientH2O brand account. Namely, the data consists of the frequency of tweets by each account in various categories as determined by human annotators through Amazon's Mechanical Turk servidce. Each of these categories are listed below:

```{r market,  echo=FALSE}

attributes(social_marketing)$names
```

Of these, we don't find "uncategorized", "chatter", "spam", and "adult" to be particularly useful in determining the interests of NutrientH20 fans, so we will remove them. Furthermore, we will remove any account with a number of spam posts greater than 10 as they are likely to be bots.

## K-means clustering
We will run k-means clustering on the refined data to see if any interesting groups appear. First let's look at k-means centers with k=2:

```{r market_1,  echo=FALSE}
clust1$centers
```
Here we see two main groups. As expected, we have those with a strong interest in personal fitness and nutrition, and a second group that represents pretty much everyone else with no clear dominant interests.

Here we add a 3rd cluster:

```{r market_2,  echo=FALSE}
clust2$centers
```

Now a third group emerges. These people are strongly interested in photo sharing, beauty, cooking, and fashion. They seem to fall in to a common "influencer" category that are more concerned with the image of health and nutrition that NutrientH2O provides rather than the nutritional benefits themselves.

Finally, we add a 4th cluster:

```{r market_3,  echo=FALSE}
clust3$centers
```

With k=4, a 4th group emerges with common interests in college/university, online gaming, and tv/film. This shows that NutrientH2O also appeals to younger people with a more sedentary lifestyle. Perhaps they simply like it for the taste or the energy it provides for studying and gaming.

## Conclusion
Three dominant groups of followers of NutrientH2O appear: nutrition/fitness enthusiasts, social media "influencer" types, and college gamers. It is thus important to market not only the scientific nutritional benefits of NutrientH2O, but also the lifestyle image it provides. For the third group, it might be beneficial to stress the taste and energy-providing aspects of NutrientH2O




